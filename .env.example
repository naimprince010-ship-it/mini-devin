# Mini-Devin Environment Configuration
# Copy this file to .env and fill in your values

# =============================================================================
# LLM Configuration (Required - at least one provider)
# =============================================================================

# Default model to use (auto-selected based on configured providers if not set)
# Options: gpt-4o, gpt-4o-mini, gpt-4-turbo, gpt-3.5-turbo,
#          claude-3-5-sonnet-20241022, claude-3-5-haiku-20241022, claude-3-opus-20240229,
#          ollama/llama3.2, ollama/codellama, ollama/mistral, ollama/mixtral,
#          azure/gpt-4o, azure/gpt-4-turbo, azure/gpt-35-turbo
LLM_MODEL=gpt-4o

# Temperature for LLM responses (0.0 - 1.0, default: 0.1)
LLM_TEMPERATURE=0.1

# -----------------------------------------------------------------------------
# OpenAI Configuration
# -----------------------------------------------------------------------------
OPENAI_API_KEY=sk-your-openai-api-key
OPENAI_API_BASE=                    # Optional: Custom API base URL
OPENAI_ORGANIZATION=                # Optional: Organization ID
OPENAI_ENABLED=true                 # Enable/disable OpenAI provider

# -----------------------------------------------------------------------------
# Anthropic Configuration (Claude models)
# -----------------------------------------------------------------------------
ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key
ANTHROPIC_API_BASE=                 # Optional: Custom API base URL
ANTHROPIC_ENABLED=true              # Enable/disable Anthropic provider

# -----------------------------------------------------------------------------
# Ollama Configuration (Local models)
# -----------------------------------------------------------------------------
OLLAMA_API_BASE=http://localhost:11434  # Ollama server URL
OLLAMA_ENABLED=true                     # Enable/disable Ollama provider

# -----------------------------------------------------------------------------
# Azure OpenAI Configuration
# -----------------------------------------------------------------------------
AZURE_API_KEY=                      # Azure OpenAI API key
AZURE_API_BASE=                     # Azure OpenAI endpoint URL
AZURE_API_VERSION=2024-02-15-preview  # API version
AZURE_DEPLOYMENT_NAME=              # Deployment name for your model
AZURE_ENABLED=false                 # Enable/disable Azure provider

# =============================================================================
# Run Mode Configuration
# =============================================================================

# Run mode determines which tools are available
# Options:
#   - offline: Terminal + Editor only (no web access)
#   - browse: Terminal + Editor + Web Search + Fetch (read-only web)
#   - interactive: All tools including interactive browser (Selenium)
RUN_MODE=offline

# =============================================================================
# Browser Search API Keys (Optional - for browse/interactive modes)
# =============================================================================

# Tavily API Key (recommended for AI-focused search)
TAVILY_API_KEY=tvly-your-tavily-api-key

# SerpAPI Key (alternative search provider)
SERPAPI_API_KEY=your-serpapi-key

# =============================================================================
# Safety Configuration
# =============================================================================

# Maximum iterations before stopping (default: 50)
MAX_ITERATIONS=50

# Maximum repair loop iterations (default: 3)
MAX_REPAIR_ITERATIONS=3

# Allow dependency file modifications (default: false)
# Set to true only if you trust the agent to modify package.json, requirements.txt, etc.
ALLOW_DEPENDENCY_BUMP=false

# Maximum lines that can be edited in a single operation (default: 300)
MAX_LINES_EDIT=300

# Maximum files that can be deleted in a single operation (default: 1)
MAX_FILES_DELETE=1

# =============================================================================
# Workspace Configuration
# =============================================================================

# Directory to mount as workspace (default: ./workspace)
WORKSPACE_DIR=./workspace

# Directory for run artifacts (default: ./runs)
RUNS_DIR=./runs

# Artifact directory inside container (default: /workspace/runs)
ARTIFACT_DIR=/workspace/runs

# =============================================================================
# Resource Limits
# =============================================================================

# CPU limit (default: 2.0 cores)
CPU_LIMIT=2.0

# Memory limit (default: 4G)
MEMORY_LIMIT=4G

# =============================================================================
# Logging Configuration
# =============================================================================

# Enable verbose logging (default: true)
VERBOSE=true

# Log level: DEBUG, INFO, WARNING, ERROR (default: INFO)
LOG_LEVEL=INFO
